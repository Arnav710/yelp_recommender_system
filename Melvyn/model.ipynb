{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id             business_id  stars\n",
      "0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw    3.0\n",
      "1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ    5.0\n",
      "2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A    3.0\n",
      "3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA    5.0\n",
      "4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ    4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load review data\n",
    "with open('yelp_academic_dataset_review.json', 'r', encoding='utf-8') as f:\n",
    "    review_data = [json.loads(line) for line in f]\n",
    "review_df = pd.DataFrame(review_data)\n",
    "\n",
    "# Filter relevant columns for baseline model\n",
    "baseline_data = review_df[['user_id', 'business_id', 'stars']]\n",
    "\n",
    "# Show sample data\n",
    "print(baseline_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data into 80% training and 20% test sets\n",
    "# train_data, test_data = train_test_split(baseline_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(f\"Training data size: {len(train_data)}\")\n",
    "# print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "sampled_data = baseline_data.sample(n=12000, random_state=42)\n",
    "train_data = sampled_data[:10000]\n",
    "test_data = sampled_data[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "import numpy as np\n",
    "\n",
    "class JaccardKNN(KNNBasic):\n",
    "    def compute_similarities(self):\n",
    "        \"\"\"Override default similarity computation with Jaccard Similarity.\"\"\"\n",
    "        n_x, n_y = self.trainset.n_users, self.trainset.n_users\n",
    "        sim = np.zeros((n_x, n_y))\n",
    "        \n",
    "        # Compute Jaccard similarity\n",
    "        for i in range(n_x):\n",
    "            for j in range(n_y):\n",
    "                u_i = set([item for (item, _) in self.trainset.ur[i]])\n",
    "                u_j = set([item for (item, _) in self.trainset.ur[j]])\n",
    "                sim[i][j] = len(u_i & u_j) / len(u_i | u_j) if len(u_i | u_j) != 0 else 0\n",
    "        return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Performance:\n",
      "RMSE: 1.4751\n",
      "MAE:  1.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2512640000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, accuracy\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(train_data[['user_id', 'business_id', 'stars']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Use Jaccard-based KNN\n",
    "model = JaccardKNN(k=20, sim_options={'user_based': True})\n",
    "model.fit(trainset)\n",
    "\n",
    "# Create test set\n",
    "testset = list(test_data.itertuples(index=False, name=None))\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Jaccard Similarity Performance:\")\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Performance:\n",
      "RMSE: 1.5092\n",
      "MAE:  1.2730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2730377777777777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, accuracy\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(train_data[['user_id', 'business_id', 'stars']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Use Jaccard-based KNN\n",
    "model = JaccardKNN(k=20, sim_options={'user_based': True})\n",
    "model.fit(trainset)\n",
    "\n",
    "# Create test set\n",
    "testset = list(test_data.itertuples(index=False, name=None))\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Jaccard Similarity Performance:\")\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
