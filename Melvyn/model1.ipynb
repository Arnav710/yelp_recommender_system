{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
      "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
      "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
      "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
      "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0    3.0       0      0     0   \n",
      "1    5.0       1      0     1   \n",
      "2    3.0       0      0     0   \n",
      "3    5.0       1      0     1   \n",
      "4    4.0       1      0     1   \n",
      "\n",
      "                                                text                 date  \n",
      "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
      "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
      "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
      "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
      "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load review data from JSON\n",
    "with open('yelp_academic_dataset_review.json', 'r', encoding='utf-8') as f:\n",
    "    review_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Create a DataFrame for reviews\n",
    "full_review_df = pd.DataFrame(review_data)\n",
    "\n",
    "# Display sample data\n",
    "print(full_review_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "import numpy as np\n",
    "\n",
    "class JaccardKNN(KNNBasic):\n",
    "    def compute_similarities(self):\n",
    "        \"\"\"Override default similarity computation with Jaccard Similarity.\"\"\"\n",
    "        n_x, n_y = self.trainset.n_users, self.trainset.n_users\n",
    "        sim = np.zeros((n_x, n_y))\n",
    "        \n",
    "        # Compute Jaccard similarity\n",
    "        for i in range(n_x):\n",
    "            for j in range(n_y):\n",
    "                u_i = set([item for (item, _) in self.trainset.ur[i]])\n",
    "                u_j = set([item for (item, _) in self.trainset.ur[j]])\n",
    "                sim[i][j] = len(u_i & u_j) / len(u_i | u_j) if len(u_i | u_j) != 0 else 0\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                      name  \\\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
      "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
      "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
      "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
      "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
      "\n",
      "                           address           city state postal_code  \\\n",
      "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
      "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
      "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
      "3                      935 Race St   Philadelphia    PA       19107   \n",
      "4                    101 Walnut St     Green Lane    PA       18054   \n",
      "\n",
      "    latitude   longitude  stars  review_count  is_open  \\\n",
      "0  34.426679 -119.711197    5.0             7        0   \n",
      "1  38.551126  -90.335695    3.0            15        1   \n",
      "2  32.223236 -110.880452    3.5            22        0   \n",
      "3  39.955505  -75.155564    4.0            80        1   \n",
      "4  40.338183  -75.471659    4.5            13        1   \n",
      "\n",
      "                                          attributes  \\\n",
      "0                      {'ByAppointmentOnly': 'True'}   \n",
      "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
      "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
      "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
      "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
      "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
      "2  Department Stores, Shopping, Fashion, Home & G...   \n",
      "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
      "4                          Brewpubs, Breweries, Food   \n",
      "\n",
      "                                               hours  \n",
      "0                                               None  \n",
      "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
      "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
      "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
      "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n"
     ]
    }
   ],
   "source": [
    "# Load business data from JSON\n",
    "with open('yelp_academic_dataset_business.json', 'r', encoding='utf-8') as f:\n",
    "    business_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Create a DataFrame for businesses\n",
    "full_business_df = pd.DataFrame(business_data)\n",
    "\n",
    "# Display sample data\n",
    "print(full_business_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_reviews(review_df, business_df, \n",
    "                   cols: list = ['user_id', 'business_id', 'stars_review'],\n",
    "                   num_samples: int = 100000):\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters review data to Philadelphia businesses and selects a subset of columns\n",
    "    Args:\n",
    "        review_df (pd.DataFrame): DataFrame containing review data\n",
    "        business_df (pd.DataFrame): DataFrame containing business data\n",
    "        cols (list, optional): Columns to keep in output DataFrame. Defaults to ['user_id', 'business_id', 'stars_review']\n",
    "        num_samples (int, optional): Number of random samples to return. If None, returns all filtered reviews\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame containing only Philadelphia business reviews with specified columns\n",
    "    \"\"\"\n",
    "        \n",
    "    # First filter businesses to only Philadelphia\n",
    "    phil_businesses = business_df[business_df['city'] == 'Philadelphia']\n",
    "\n",
    "    # Merge with reviews to get only Philadelphia reviews\n",
    "    filtered_reviews = pd.merge(review_df, phil_businesses, on='business_id', how='inner', suffixes=('_review', '_business'))\n",
    "    \n",
    "    if num_samples is None:\n",
    "        return filtered_reviews[cols]\n",
    "        \n",
    "    return filtered_reviews.sample(n=num_samples, random_state=42)[cols]\n",
    "review_df = filter_reviews(full_review_df, full_business_df, num_samples=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 90000\n",
      "Test data size: 10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming review_df contains 'user_id', 'business_id', and 'stars' columns\n",
    "train_data, test_data = train_test_split(review_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print sizes for confirmation\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise import accuracy\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load training data into Surprise format\n",
    "trainset = Dataset.load_from_df(train_data[['user_id', 'business_id', 'stars_review']], reader).build_full_trainset()\n",
    "\n",
    "# Prepare the test set as a list of tuples (user_id, business_id, stars)\n",
    "testset = list(test_data.itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance:\n",
      "RMSE: 1.4172\n",
      "MAE:  1.1703\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the User-User KNN model\n",
    "# Train the Jaccard-based KNN model\n",
    "jaccard_knn = JaccardKNN(k=20, sim_options={'user_based': True})  # Use top 20 similar users\n",
    "jaccard_knn.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = jaccard_knn.test(testset)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Baseline Model Performance:\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 18000\n",
      "Test data size: 2000\n",
      "Baseline Model Performance:\n",
      "MSE: 1.8271\n",
      "RMSE: 1.3517\n",
      "MAE:  1.1231\n"
     ]
    }
   ],
   "source": [
    "review_df = filter_reviews(full_review_df, full_business_df, num_samples=20000)\n",
    "# Assuming review_df contains 'user_id', 'business_id', and 'stars' columns\n",
    "train_data, test_data = train_test_split(review_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print sizes for confirmation\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise import accuracy\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load training data into Surprise format\n",
    "trainset = Dataset.load_from_df(train_data[['user_id', 'business_id', 'stars_review']], reader).build_full_trainset()\n",
    "\n",
    "# Prepare the test set as a list of tuples (user_id, business_id, stars)\n",
    "testset = list(test_data.itertuples(index=False, name=None))\n",
    "\n",
    "# Initialize and train the User-User KNN model\n",
    "# Train the Jaccard-based KNN model\n",
    "jaccard_knn = JaccardKNN(k=10, sim_options={'user_based': True})  # Use top 20 similar users\n",
    "jaccard_knn.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = jaccard_knn.test(testset)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Baseline Model Performance:\")\n",
    "mse = accuracy.mse(predictions)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
